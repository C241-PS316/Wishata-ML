{"cells":[{"cell_type":"markdown","metadata":{"id":"_9n6wDC1PxC2"},"source":["# Import Library"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6152,"status":"ok","timestamp":1718003243624,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"ZdWSoiFh8_Ub"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from keras_preprocessing.image import ImageDataGenerator\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, concatenate\n","from keras.optimizers import Adam\n","from keras.applications import MobileNetV2\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from keras.regularizers import l2\n","from keras.preprocessing import image\n","import numpy as np\n","from keras.models import load_model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24132,"status":"ok","timestamp":1718003267751,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"z3Zce2FEfBrS","outputId":"3bd05cd2-9c6f-4f6a-d7cd-a2ece178f0d1"},"outputs":[],"source":["# Definisikan path ke direktori data\n","base_dir = 'Datasets'\n","features = ['scenery', 'environment', 'category']\n","\n","# Fungsi untuk menghitung jumlah file dalam direktori\n","def count_files_in_directory(directory):\n","    total_files = 0\n","    for root, dirs, files in os.walk(directory):\n","        total_files += len([file for file in files if file.endswith(('.jpg', '.jpeg', '.png', '.webp'))])\n","    return total_files\n","\n","# Menghitung jumlah file untuk setiap fitur dan labela\n","for feature in features:\n","    feature_dir = os.path.join(base_dir, feature)\n","    print(f'Output: {feature}')\n","    for label in os.listdir(feature_dir):\n","        label_dir = os.path.join(feature_dir, label)\n","        if os.path.isdir(label_dir):\n","            num_files = count_files_in_directory(label_dir)\n","            print(f'  Label: {label}, Number of files: {num_files}')\n"]},{"cell_type":"markdown","metadata":{"id":"qpAifpxGP2eE"},"source":["# Data Pre-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1718003267751,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"Ui-rGq4EDxKG"},"outputs":[],"source":["sce_dir = os.path.join(base_dir, 'scenery')\n","env_dir = os.path.join(base_dir, 'environment')\n","cat_dir = os.path.join(base_dir, 'category')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1257,"status":"ok","timestamp":1718003268965,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"HFGNwUi9ADde","outputId":"57f73670-5096-4738-cc44-645915336509"},"outputs":[],"source":["# Tentukan ukuran gambar yang diinginkan\n","img_width, img_height = 224, 224\n","batch_size = 32\n","\n","# Fungsi untuk membuat generator dengan data augmentation\n","def create_gen(base_dir, img_width, img_height, batch_size, subset):\n","    if subset == 'training':\n","        datagen = ImageDataGenerator(\n","            rescale=1./255,\n","            rotation_range=45,\n","            width_shift_range=0.3,\n","            height_shift_range=0.3,\n","            shear_range=0.3,\n","            zoom_range=0.3,\n","            horizontal_flip=True,\n","            brightness_range=[0.8, 1.2],\n","            validation_split=0.2\n","        )\n","    else:\n","        datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","    generator = datagen.flow_from_directory(\n","        base_dir,\n","        target_size=(img_width, img_height),\n","        batch_size=batch_size,\n","        class_mode='categorical',\n","        subset=subset,\n","        shuffle=True)\n","    return generator\n","\n","# Membuat generator untuk setiap fitur\n","sce_train_gen = create_gen(sce_dir, img_width, img_height, batch_size, 'training')\n","env_train_gen = create_gen(env_dir, img_width, img_height, batch_size, 'training')\n","cat_train_gen = create_gen(cat_dir, img_width, img_height, batch_size, 'training')\n","\n","sce_val_gen = create_gen(sce_dir, img_width, img_height, batch_size, 'validation')\n","env_val_gen = create_gen(env_dir, img_width, img_height, batch_size, 'validation')\n","cat_val_gen = create_gen(cat_dir, img_width, img_height, batch_size, 'validation')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718003268966,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"NYbKylyLUq9A"},"outputs":[],"source":["def show_example_images(generator, images_per_class=1):\n","    class_indices = generator.class_indices\n","    class_names = list(class_indices.keys())\n","    \n","    images, labels = next(generator)\n","\n","    # Create a list to store selected images and their corresponding labels\n","    selected_images = []\n","    selected_labels = []\n","\n","    # Iterate through each class and select a specified number of images\n","    for class_name in class_names:\n","        class_index = class_indices[class_name]\n","        class_images = [img for img, lbl in zip(images, labels) if np.argmax(lbl) == class_index]\n","        class_labels = [lbl for lbl in labels if np.argmax(lbl) == class_index]\n","\n","        # If there are fewer images than requested, use all available images\n","        if len(class_images) < images_per_class:\n","            selected_images.extend(class_images)\n","            selected_labels.extend(class_labels)\n","        else:\n","            selected_indices = random.sample(range(len(class_images)), images_per_class)\n","            selected_images.extend([class_images[idx] for idx in selected_indices])\n","            selected_labels.extend([class_labels[idx] for idx in selected_indices])\n","\n","    num_images = len(selected_images)\n","    \n","    # Plot the images\n","    plt.figure(figsize=(15, 5))\n","    for i in range(num_images):\n","        ax = plt.subplot(1, num_images, i + 1)\n","        plt.imshow(selected_images[i])\n","        plt.axis(\"off\")\n","\n","        class_index = np.argmax(selected_labels[i])\n","        class_name = class_names[class_index]\n","\n","        plt.title(class_name, fontsize=12)\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"executionInfo":{"elapsed":61734,"status":"ok","timestamp":1718003330696,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"4jKLZTzeUxOg","outputId":"92f9a48b-8ef0-4ccd-fea2-dcdfccb17f7d"},"outputs":[],"source":["# Menampilkan contoh gambar dari train_generator\n","show_example_images(sce_train_gen, images_per_class=1)  \n","show_example_images(env_train_gen, images_per_class=1)  \n","show_example_images(cat_train_gen, images_per_class=1)  \n"]},{"cell_type":"markdown","metadata":{"id":"-_UzJcN5QaNZ"},"source":["# Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6943,"status":"ok","timestamp":1718006864261,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"IuxpRryNDBo2"},"outputs":[],"source":["base_model = MobileNetV2(include_top=False, input_shape=(img_width, img_height, 3), weights='imagenet')\n","\n","# Unfreeze some of the layers in the base model\n","for layer in base_model.layers[-50:]:\n","    layer.trainable = True\n","\n","inputs = Input(shape=(img_width, img_height, 3))\n","x = base_model(inputs, training=True)\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n","\n","# Output scenery\n","scenery = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n","scenery = Dropout(0.5)(scenery)\n","scenery = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(scenery)\n","scenery = Dropout(0.5)(scenery)\n","scenery = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(scenery)\n","scenery = Dropout(0.5)(scenery)\n","scenery_output = Dense(2, activation='sigmoid', name='scenery')(scenery)\n","\n","# Output environment\n","environment = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n","environment = Dropout(0.5)(environment)\n","environment = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(environment)\n","environment = Dropout(0.5)(environment)\n","environment = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(environment)\n","environment = Dropout(0.5)(environment)\n","environment_output = Dense(2, activation='sigmoid', name='environment')(environment)\n","\n","# Output category\n","category = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n","category = Dropout(0.5)(category)\n","category = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(category)\n","category = Dropout(0.5)(category)\n","category = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(category)\n","category = Dropout(0.5)(category)\n","category_output = Dense(3, activation='sigmoid', name='category')(category)\n","\n","sce_model = Model(inputs=inputs, outputs=scenery_output)\n","env_model = Model(inputs=inputs, outputs=environment_output)\n","cat_model = Model(inputs=inputs, outputs=category_output)\n","\n","# Compile the model with a different learning rate\n","learning_rate = 0.0001\n","\n","sce_opt = Adam(learning_rate=learning_rate)\n","env_opt = Adam(learning_rate=learning_rate)\n","cat_opt = Adam(learning_rate=learning_rate)\n","\n","sce_model.compile(optimizer=sce_opt,\n","              loss={'scenery': 'binary_crossentropy'},\n","              metrics={'scenery': 'accuracy'})\n","env_model.compile(optimizer=env_opt,\n","              loss={'environment': 'binary_crossentropy'},\n","              metrics={'environment': 'accuracy'})\n","cat_model.compile(optimizer=cat_opt,\n","              loss={'category': 'categorical_crossentropy'},\n","              metrics={'category': 'accuracy'})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":785,"status":"ok","timestamp":1718006866700,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"Wt3M2XBHqI95","outputId":"3cd6629c-4041-41e9-f1d2-2726f344c5fb"},"outputs":[],"source":["sce_model.summary()\n","env_model.summary()\n","cat_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"Udy8JRfJQeFz"},"source":["# Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5803755,"status":"ok","timestamp":1718012685159,"user":{"displayName":"Muhammad Harits Shofwan Adani M121D4KY2977","userId":"05042013223859728863"},"user_tz":-420},"id":"HaYaRUDgQgXf","outputId":"e0a64654-5668-4e11-adc3-02b3907e9cad"},"outputs":[],"source":["# Adding callbacks for early stopping and learning rate reduction\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n","\n","\n","scenery_history = sce_model.fit(\n","    sce_train_gen,\n","    validation_data=sce_val_gen,\n","    epochs=50,\n","    callbacks=[early_stopping, reduce_lr]\n",")\n","\n","# Train environment output\n","environment_history = env_model.fit(\n","    env_train_gen,\n","    validation_data=env_val_gen,\n","    epochs=50,\n","    callbacks=[early_stopping, reduce_lr]\n",")\n","\n","# Train category output\n","category_history = cat_model.fit(\n","    cat_train_gen,\n","    validation_data=cat_val_gen,\n","    epochs=50,\n","    callbacks=[early_stopping, reduce_lr]\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"L9mW5jFnQjF-"},"source":["# Evaluation and Save the Model"]},{"cell_type":"markdown","metadata":{},"source":["## SaveModel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","\n","# Assuming you have trained your models with model.fit()\n","\n","# Save scenery model\n","tf.saved_model.save(sce_model, 'Model50/scenery_model')\n","\n","# Save environment model\n","tf.saved_model.save(env_model, 'Model50/environment_model')\n","\n","# Save category model\n","tf.saved_model.save(cat_model, 'Model50/category_model')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Keras & h5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save scenery model\n","sce_model.save(\"Model20/sce_model.keras\")\n","\n","# Save environment model\n","env_model.save(\"Model20/env_model.keras\")\n","\n","# Save category model\n","cat_model.save(\"Model20/cat_model.keras\")\n","\n","# Save scenery model\n","sce_model.save(\"Model20/sce_model.h5\")\n","\n","# Save environment model\n","env_model.save(\"Model20/env_model.h5\")\n","\n","# Save category model\n","cat_model.save(\"Model20/cat_model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define input layer\n","\n","img_width, img_height = 224,224\n","input_layer = Input(shape=(img_width, img_height, 3))\n","\n","# Get the outputs from each individual model\n","scenery_output = sce_model(input_layer)\n","environment_output = env_model(input_layer)\n","category_output = cat_model(input_layer)\n","\n","# Combine the outputs into a single list\n","combined_outputs = [scenery_output, environment_output, category_output]\n","\n","# Create the combined model\n","combined_model = Model(inputs=input_layer, outputs=combined_outputs)\n","\n","# Compile the combined model\n","# You need to define appropriate loss functions and metrics for each output\n","combined_model.compile(optimizer='adam', \n","                       loss=['binary_crossentropy', 'binary_crossentropy', 'categorical_crossentropy'],\n","                       metrics=['accuracy', 'accuracy', 'accuracy'])\n","\n","# Summary of the combined model\n","combined_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["combined_model.save(\"Model20/combined_model.keras\")\n","combined_model.save(\"Model20/combined_model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loaded_combined_model = load_model(\"Model20/combined_model.h5\")\n","# Load an example image from the dataset\n","image_path = \"Test/test1.jpg\" \n","test_image = image.load_img(image_path, target_size=(img_width, img_height))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis=0)\n","\n","# Preprocess the image\n","test_image = test_image / 255.0  # Normalize pixel values to [0, 1]\n","\n","# Make predictions using the combined model\n","predictions = loaded_combined_model.predict(test_image)\n","\n","# Interpret the predictions\n","scenery_prediction = predictions[0]  # Output for scenery\n","environment_prediction = predictions[1]  # Output for environment\n","category_prediction = predictions[2]  # Output for category\n","\n","# Example: Print the predicted labels\n","print(\"Scenery Prediction:\", scenery_prediction)\n","print(\"Environment Prediction:\", environment_prediction)\n","print(\"Category Prediction:\", category_prediction)\n","\n","# Define the class labels for interpretation\n","scenery_classes = ['Nature', 'Urban']\n","environment_classes = ['Land', 'Water']\n","category_classes = ['Attraction', 'Greenery', 'Historical']\n","\n","# Show the image\n","plt.imshow(test_image[0])\n","plt.axis('off')\n","\n","# Add text annotations for predictions\n","scenery_label = scenery_classes[np.argmax(scenery_prediction)]\n","environment_label = environment_classes[np.argmax(environment_prediction)]\n","category_label = category_classes[np.argmax(category_prediction)]\n","\n","plt.text(10, 30, f\"Scenery Prediction: {scenery_label}\", fontsize=12, color='white', backgroundcolor='black')\n","plt.text(10, 60, f\"Environment Prediction: {environment_label}\", fontsize=12, color='white', backgroundcolor='black')\n","plt.text(10, 90, f\"Category Prediction: {category_label}\", fontsize=12, color='white', backgroundcolor='black')\n","\n","plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_hJaJiZYQplC"},"source":["# Convert to TFLite"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = tf.keras.models.load_model('Model20/sce_model.keras')\n","\n","model.summary()\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_ops = [\n","    tf.lite.OpsSet.TFLITE_BUILTINS,  # TensorFlow Lite builtin operations\n","    tf.lite.OpsSet.SELECT_TF_OPS     # TensorFlow operations\n","]\n","converter.experimental_new_converter = True\n","\n","try:\n","    tflite_model = converter.convert()\n","    # Save the converted model\n","    with open(\"Model20/sce_model.tflite\", \"wb\") as f:\n","        f.write(tflite_model)\n","    print(\"Model conversion successful.\")\n","except Exception as e:\n","    print(\"Error during model conversion:\", str(e))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = tf.keras.models.load_model('Model20/env_model.keras')\n","\n","model.summary()\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_ops = [\n","    tf.lite.OpsSet.TFLITE_BUILTINS,  # TensorFlow Lite builtin operations\n","    tf.lite.OpsSet.SELECT_TF_OPS     # TensorFlow operations\n","]\n","converter.experimental_new_converter = True\n","\n","try:\n","    tflite_model = converter.convert()\n","    # Save the converted model\n","    with open(\"Model20/env_model.tflite\", \"wb\") as f:\n","        f.write(tflite_model)\n","    print(\"Model conversion successful.\")\n","except Exception as e:\n","    print(\"Error during model conversion:\", str(e))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = tf.keras.models.load_model('Model20/cat_model.keras')\n","\n","model.summary()\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_ops = [\n","    tf.lite.OpsSet.TFLITE_BUILTINS,  # TensorFlow Lite builtin operations\n","    tf.lite.OpsSet.SELECT_TF_OPS     # TensorFlow operations\n","]\n","converter.experimental_new_converter = True\n","\n","try:\n","    tflite_model = converter.convert()\n","    # Save the converted model\n","    with open(\"Model20/cat_model.tflite\", \"wb\") as f:\n","        f.write(tflite_model)\n","    print(\"Model conversion successful.\")\n","except Exception as e:\n","    print(\"Error during model conversion:\", str(e))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
